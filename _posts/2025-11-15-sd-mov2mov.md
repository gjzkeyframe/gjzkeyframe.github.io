---
title: AI 教程：使用 Mov2mov 生成视频
description: ControlNet 是一种通过添加额外条件来控制扩散模型的神经网络结构。
author: Keyframe
date: 2025-11-15 08:08:08 +0800
categories: [AI 教程]
tags: [AI 教程, AI, AIGC, Stable Diffusion, Mov2mov]
pin: false
math: true
mermaid: true
image:
  path: assets/resource/aigc-tutorial/sd-mov2mov/sd-mov2mov-001.png
  alt: Stable Diffusion 生成视频
---


>向你推荐 **<a href="https://apps.apple.com/app/id6752116909" target="_blank">FaceXSwap</a>**：On-Device Offline AI Face Swap for Free
>
>在 iPhone 上直接对照片、GIF 动图、视频中的人脸实现快速换脸。无需上传任何数据，确保完全隐私与安全。即时、安全、无限次数、功能强大，现在即可免费试用。
>
>![在 AppStore 搜索 'facexswap'](assets/resource/aigc-product/facexswap-2.png)
>_在 AppStore 搜索 'facexswap'_
>
>- FaceXSwap 官网：<a href="https://facexswap.com" target="_blank">https://facexswap.com</a>
>- FaceXSwap iOS App 下载：<a href="https://apps.apple.com/app/id6752116909" target="_blank">https://apps.apple.com/app/id6752116909</a>
{: .prompt-tip }

---


我们前面介绍的 Stable Diffusion WebUI 的功能主要是应用在图像生成和处理方面，不过借助一款名为 `Mov2mov` 的插件我们还可以使用 WebUI 来生成视频。

在很多场景下，我们需要将不同视频进行风格化处理，例如真人视频转为动漫视频，借助 `Mov2mov` 插件我们可以便捷高效的完成这样的处理。`Mov2mov` 本质上是把视频中的每一帧图像截取出来，再使用 Stable Diffusion 进行风格重绘，再将重绘后的图像拼接编码成一个完整的视频。


安装 `Mov2mov` 插件和安装 `ControlNet` 等插件类似，流程如下：

- 1）打开 `Extensions` 栏；
- 2）打开 `Extensions` 栏下的 `Install from URL` 栏；
- 3）在 `URL for extension's git repository` 下的输入框中输入 `https://github.com/Scholar01/sd-webui-mov2mov`；
- 4）点击 `Install` 按钮，等待安装成功；
- 5）重启 Stable Diffusion WebUI。


![安装 Mov2mov 插件](assets/resource/aigc-tutorial/sd-mov2mov/sd-mov2mov-003.png)

![安装 Mov2mov 插件](assets/resource/aigc-tutorial/sd-mov2mov/sd-mov2mov-004.png)







## 1、Mov2mov 应用

当我们安装好 `Mov2mov` 插件并重启 WebUI 后，在顶层功能栏目会多出一个 `Mov2mov` 栏，我们选择它即打开了 `Mov2mov` 功能页面。使用方式如图：

![Mov2mov 使用](assets/resource/aigc-tutorial/sd-mov2mov/sd-mov2mov-000.png)

- 1）在顶部栏目中，选择 `Mov2mov` 栏目；
- 2）在 `Mov2mov` 子面板中导入原视频；
- 3）在提示词输入区输入`提示词（Prompt）`和`负向提示词（Negative prompt）`，这里主要是描述新生成画面的内容；
- 4）通过 `width` 和 `height` 设置输出视频的分辨率，这里尽量保持与原视频分辨率比例一致，但建议不要设置过高，目标分辨率设置越高则生成任务耗时越久；
- 5）通过 `Generate Movie Mode` 参数设置生成视频的编码格式；
- 6）通过 `Denoising strength` 参数设置降噪强度，该参数值越小越接近原图，建议不要超过 `0.5`；
- 7）通过 `Movie Frames` 参数设置输出视频帧率，表示 1 秒内生成多少张图片，该参数值越大，视频看起来越连贯，但生成任务耗时越久，该参数建议值是 `24` 或 `30`；
- 8）通过 `Max Frames` 参数设置生成帧数，例如可以先设置为 `1`，代表仅生成第一帧，验证生成效果较好再设置多帧，`-1` 代表生成全部帧；
- 9）点击 `Generate` 开始生成任务；
- 10）等待生成结果。








下面是原视频以及我们使用上述过程处理后的视频，左原视频、中间 0.25 重绘幅度、右 0.5 重绘幅度，重绘幅度越大与原视频差异越大：

![Mov2mov使用](assets/resource/aigc-tutorial/sd-mov2mov/sd-mov2mov-001.png)



## 2、Mov2mov 结合 ControlNet

`Mov2mov` 功能还可以结合 `ControlNet` 来控制画面结构，相对于上面的流程，主要区别如图：

![Mov2mov 结合 ControlNet 使用](assets/resource/aigc-tutorial/sd-mov2mov/sd-mov2mov-002.png)


- 1）在 `ControlNet` 面板中开启 ControlNet 功能；
- 2）在 `ControlNet` 面板中导入引导图；
- 3）选择 `ControlNet` 预处理器和模型；
- 4）设置其他 `ControlNet` 参数；
- 5）调高 `Denoising strength` 降噪强度值，因为这里要通过 ControlNet 来改变画面结构了，所以需要调高该参数值。




